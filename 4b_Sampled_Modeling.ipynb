{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction:-Predicting-if-the-Question-is-Answered\" data-toc-modified-id=\"Introduction:-Predicting-if-the-Question-is-Answered-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction: Predicting if the Question is Answered</a></span></li><li><span><a href=\"#Data-Frame-1\" data-toc-modified-id=\"Data-Frame-1-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Frame 1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-in-DataFrame\" data-toc-modified-id=\"Reading-in-DataFrame-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Reading in DataFrame</a></span></li><li><span><a href=\"#Baseline-Accuracy\" data-toc-modified-id=\"Baseline-Accuracy-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Baseline Accuracy</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Removing-Duplicate-Rows\" data-toc-modified-id=\"Removing-Duplicate-Rows-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Removing Duplicate Rows</a></span></li><li><span><a href=\"#Transforming-Data-With-FunctionTransformer\" data-toc-modified-id=\"Transforming-Data-With-FunctionTransformer-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Transforming Data With FunctionTransformer</a></span></li><li><span><a href=\"#Sampling-the-Data-In-Order-to-Create-Even-Classes\" data-toc-modified-id=\"Sampling-the-Data-In-Order-to-Create-Even-Classes-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Sampling the Data In Order to Create Even Classes</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Instantiating-X-and-y-variables\" data-toc-modified-id=\"Instantiating-X-and-y-variables-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Instantiating X and y variables</a></span></li><li><span><a href=\"#Train-Test-Split\" data-toc-modified-id=\"Train-Test-Split-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Train Test Split</a></span></li><li><span><a href=\"#Logistic-Regression-Gridsearch\" data-toc-modified-id=\"Logistic-Regression-Gridsearch-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Logistic Regression Gridsearch</a></span></li><li><span><a href=\"#KNN-Gridsearch\" data-toc-modified-id=\"KNN-Gridsearch-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>KNN Gridsearch</a></span></li><li><span><a href=\"#Random-Forest-Gridsearch\" data-toc-modified-id=\"Random-Forest-Gridsearch-2.4.5\"><span class=\"toc-item-num\">2.4.5&nbsp;&nbsp;</span>Random Forest Gridsearch</a></span></li></ul></li><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Confusion Matrix</a></span><ul class=\"toc-item\"><li><span><a href=\"#Function-Definition\" data-toc-modified-id=\"Function-Definition-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Function Definition</a></span></li><li><span><a href=\"#Function-Execution:-Confusion-Matrix-Results\" data-toc-modified-id=\"Function-Execution:-Confusion-Matrix-Results-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Function Execution: Confusion Matrix Results</a></span></li></ul></li></ul></li><li><span><a href=\"#Data-Frame-2\" data-toc-modified-id=\"Data-Frame-2-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Frame 2</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression-Gridsearch\" data-toc-modified-id=\"Logistic-Regression-Gridsearch-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Logistic Regression Gridsearch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Words-Most-Indicative-of-a-Question-Being-Answered.\" data-toc-modified-id=\"Words-Most-Indicative-of-a-Question-Being-Answered.-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Words Most Indicative of a Question Being Answered.</a></span></li></ul></li><li><span><a href=\"#Thank-You!!\" data-toc-modified-id=\"Thank-You!!-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Thank You!!</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampled Modeling\n",
    "\n",
    "## Introduction: Predicting if the Question is Answered\n",
    "\n",
    "To better understand the impact of how a question is asked, I built a model to see how well I could predict if a question was answered based on the question text and the question score. In this notebook, I grid-search over two dataframes with several models.\n",
    "\n",
    "*Dataframe 1:*\n",
    "In the unsampled model from the notebook \"4a_Unsampled_Modeling.ipynb\", I performed a grid-search over the whole data frame using `questions_body` and `questions_score` as features. Since the classes were highly unbalanced (answerd vs. un-answered), with a 98% baseline score, I decided to sample the data to even out the classes. Additionally, I removed duplicate data by removing answer and tag data and replacing them with a \"was_answered\" and \"has_tag\" boolean column. Both the `questions_body` and `questions_score` were kept as features. \n",
    "\n",
    "*Dataframe 2:*\n",
    "In the second dataframe, I used the same sampled dataframe as in \"dataframe 1\" but dropped the `questions_score` feature, since I hypothesized that `question_score` was a strong indicator of a question being answered. Additionally, it is easier to get real-time feedback on the text of your question, versus waiting for others to up-vote it, in order to increase your chances of the question being answered.\n",
    "\n",
    "For the first dataframe, I grid-searched over Logistic Regression, K-Nearest Neighbors, and Random Forest, with Random Forest Providing the best results. \n",
    "\n",
    "In the second dataframe I only used Logicstic Regression due to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #General\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "    #Exporting python objects for later recall\n",
    "# using dill to export the GridSearchCV object\n",
    "# dill is an augmented version of pickle github.com/uqfoundation/dill\n",
    "# Since the GridSearchCV object contains a lambda function, regular pickle cannot dump or load it\n",
    "# also note that we are not using joblib here since we are not saving off large (>4GB) numpy arrays\n",
    "import dill as pickle\n",
    "\n",
    "\n",
    "    #Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "    #Sklearn Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn.feature_extraction import stop_words, text\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    #Suppress FutureWarning messages\\n\",\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame 1\n",
    "\n",
    "### Reading in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datasets/cleaned_4_modeling.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id              0\n",
       "questions_author_id       0\n",
       "questions_date_added      0\n",
       "questions_title           0\n",
       "questions_body            0\n",
       "questions_score           8\n",
       "was_answered              0\n",
       "answers_score           837\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this classification model, we're not going to use the answers_score column and so I will drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='answers_score', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51944, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 8 rows with nulls out of about 52k, dropping the rows where there are nulls in the questions_score will not significantly affect the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis = 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy\n",
    "\n",
    "Since most of the questions are answered the classes are highly unbalanced with 98% Baseline Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline: 0.9841920825631546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0    51115\n",
       "0.0      821\n",
       "Name: was_answered, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"baseline:\", df['was_answered'].mean())\n",
    "df['was_answered'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23928, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Data With FunctionTransformer\n",
    "\n",
    "In order to format the data for modeling I'm using a Function Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_text_data = FunctionTransformer(lambda x: x['questions_body'], validate = False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['questions_score',]], validate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling the Data In Order to Create Even Classes\n",
    "\n",
    "Since the classes above are so unbalanced I'm only taking a sample of the data where the question was answered. This creates a new baseline accuracy near 50% so we can actually model and test how much impact our features have on being able to predict if the question is answered or not. If we did not balance the classes, the model could just predict a question as answered every time and it would be 98% correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating portioned dataframes that have even classes of the dataframe where questions were and were not answered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_was = df[df['was_answered']==1].sample(n=900)\n",
    "df_wasnt = df[df['was_answered']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating the portioned dataframes above back into one dataframe to be used in modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.concat([df_was, df_wasnt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the new baseline accuracy score so we can compare how the models performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5229517722254503"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['was_answered'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiating X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sample_df['was_answered']\n",
    "X = sample_df[['questions_body','questions_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the data to access later if it is desired to re-run the models using the same train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle(\"./pickles/X_train_4b.pkl\")\n",
    "X_test.to_pickle(\"./pickles/X_test_4b.pkl\")\n",
    "y_train.to_pickle(\"./pickles/y_train_4b.pkl\")\n",
    "y_test.to_pickle(\"./pickles/y_test_4b.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_loaded = pd.read_pickle(\"./pickles/X_train_4b.pkl\")\n",
    "X_test_loaded = pd.read_pickle(\"./pickles/X_test_4b.pkl\")\n",
    "y_train_loaded = pd.read_pickle(\"./pickles/y_train_4b.pkl\")\n",
    "y_test_loaded = pd.read_pickle(\"./pickles/y_test_4b.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Pipeline to Grid Search Using Standard Scaler, Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_logreg = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "            ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer())\n",
    "            ]))\n",
    "    ])),\n",
    "    ('logreg', LogisticRegression(solver='liblinear'))\n",
    "])\n",
    "\n",
    "params_logreg = {\n",
    "           'logreg__penalty' : ['l1', 'l2']\n",
    "}\n",
    "\n",
    "gs_logreg = GridSearchCV(pipe_logreg, params_logreg, cv=5)\n",
    "gs_logreg.fit(X_train, y_train)\n",
    "\n",
    "with open(\"./pickles/gs_logreg_4b.pkl\", 'wb') as f:\n",
    "    pickle.dump(gs_logreg, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.9170542635658915\n",
      "test score 0.765661252900232\n",
      "best params: {'logreg__penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "# re-load grid-search object so do not have to re-run the model if accessing notebook later\n",
    "with open(\"./pickles/gs_logreg_4b.pkl\", 'rb') as f:\n",
    "    gs_logreg_loaded = pickle.load(f)\n",
    "\n",
    "print(\"train score\", gs_logreg_loaded.score(X_train_loaded, y_train_loaded))\n",
    "print(\"test score\", gs_logreg_loaded.score(X_test_loaded, y_test_loaded))\n",
    "print(\"best params:\", gs_logreg_loaded.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_knn = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "            ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer())\n",
    "            ]))\n",
    "    ])),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "\n",
    "])\n",
    "\n",
    "params_knn = {\n",
    "    'knn__n_neighbors' : [3, 5, 10, 15, 20],\n",
    "#     'knn__metric': ['euclidean', 'manhattan']  #Takes a while to run\n",
    "\n",
    "}\n",
    "\n",
    "gs_knn = GridSearchCV(pipe_knn, params_knn, cv=5)\n",
    "gs_knn.fit(X_train, y_train)\n",
    "\n",
    "with open(\"./pickles/gs_knn_4b.pkl\", 'wb') as f:\n",
    "    pickle.dump(gs_knn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8054263565891473\n",
      "test score 0.654292343387471\n",
      "best params: {'knn__n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "# re-load grid-search object so do not have to re-run the model if accessing notebook later\n",
    "with open(\"./pickles/gs_knn_4b.pkl\", 'rb') as f:\n",
    "    gs_knn_loaded = pickle.load(f)\n",
    "\n",
    "print(\"train score\", gs_knn_loaded.score(X_train_loaded, y_train_loaded))\n",
    "print(\"test score\", gs_knn_loaded.score(X_test_loaded, y_test_loaded))\n",
    "print(\"best params:\", gs_knn_loaded.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "            ('numeric_features', Pipeline([\n",
    "                ('selector', get_numeric_data),\n",
    "                ('ss', StandardScaler())\n",
    "            ])),\n",
    "            ('text_features', Pipeline([\n",
    "                ('selector', get_text_data),\n",
    "                ('cvec', CountVectorizer())\n",
    "            ]))\n",
    "    ])),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "\n",
    "])\n",
    "\n",
    "params_rf = {\n",
    "    'rf__n_estimators': [100,125],\n",
    "    'rf__max_depth': [None, 4, 5, 6],\n",
    "    'rf__max_features': [None,\"auto\"]}\n",
    "    \n",
    "\n",
    "gs_rf = GridSearchCV(pipe_rf, params_rf, cv=5)\n",
    "gs_rf.fit(X_train, y_train)\n",
    "\n",
    "with open(\"./pickles/gs_rf_4b.pkl\", 'wb') as f:\n",
    "    pickle.dump(gs_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score 0.8612403100775193\n",
      "test score 0.8097447795823666\n",
      "best params: {'rf__max_depth': 5, 'rf__max_features': None, 'rf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# re-load grid-search object so do not have to re-run the model if accessing notebook later\n",
    "with open(\"./pickles/gs_rf_4b.pkl\", 'rb') as f:\n",
    "    gs_rf_loaded = pickle.load(f)\n",
    "\n",
    "print(\"train score\", gs_rf_loaded.score(X_train_loaded, y_train_loaded))\n",
    "print(\"test score\", gs_rf_loaded.score(X_test_loaded, y_test_loaded))\n",
    "print(\"best params:\", gs_rf_loaded.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Definition\n",
    "\n",
    "Defining a Function that Returns a Confusion Matrix as a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix provides evaluation metrics that highlight how the model is being accurate and erroneous. The confusion matrix below shows scores from the Random Forest Model which had the best prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion(y_test, preds, classes):\n",
    "\n",
    "    conmat = confusion_matrix(y_test, preds)\n",
    "    print(f'Accuracy Score: {accuracy_score(y_test, preds)}')\n",
    "    print(f'Precision Score: {precision_score(y_test, preds)}')\n",
    "    print(f'Recall Score: {recall_score(y_test, preds)}')\n",
    "    return pd.DataFrame(conmat, columns=['Predicted ' +class_ for class_ in classes], \\\n",
    "                index=['Actual '+ class_ for class_ in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Execution: Confusion Matrix Results\n",
    "\n",
    "Calling `make_confusion` function to get Accuracy, Precision and Recalls Scores and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.8097447795823666\n",
      "Precision Score: 0.7769516728624535\n",
      "Recall Score: 0.9047619047619048\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted wasn't answered</th>\n",
       "      <th>Predicted was answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual wasn't answered</th>\n",
       "      <td>140</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual was answered</th>\n",
       "      <td>22</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted wasn't answered  Predicted was answered\n",
       "Actual wasn't answered                        140                      60\n",
       "Actual was answered                            22                     209"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a function to print out a nice confusion matrix\n",
    "preds = gs_rf_loaded.best_estimator_.predict(X_test)\n",
    "\n",
    "make_confusion(y_test, preds, [\"wasn't answered\", \"was answered\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Frame 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully modeling if a question will be answered or not based on question body and score, I wanted to know how we could predict just on question body since score was a likely tell. Below, I modeled using a pipeline and grid-searching with logistic regression. This data set still uses the sampled data and balanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the X and Y variable, with only `questions_body` used as a predictor for y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sample_df['was_answered']\n",
    "X = sample_df['questions_body']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,\n",
    "                                                   y,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle the data to access later if it is desired to re-run the models using the same train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.to_pickle(\"./pickles/X_train2_4b.pkl\")\n",
    "X_test2.to_pickle(\"./pickles/X_test2_4b.pkl\")\n",
    "y_train2.to_pickle(\"./pickles/y_train2_4b.pkl\")\n",
    "y_test2.to_pickle(\"./pickles/y_test2_4b.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2_loaded = pd.read_pickle(\"./pickles/X_train2_4b.pkl\")\n",
    "X_test2_loaded = pd.read_pickle(\"./pickles/X_test2_4b.pkl\")\n",
    "y_train2_loaded = pd.read_pickle(\"./pickles/y_train2_4b.pkl\")\n",
    "y_test2_loaded = pd.read_pickle(\"./pickles/y_test2_4b.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "80 fits failed out of a total of 160.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "80 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.66589147        nan 0.69224806        nan 0.65891473\n",
      "        nan 0.67906977        nan 0.66744186        nan 0.69767442\n",
      "        nan 0.6620155         nan 0.68527132        nan 0.66976744\n",
      "        nan 0.69612403        nan 0.6620155         nan 0.69069767\n",
      "        nan 0.66976744        nan 0.69612403        nan 0.6627907\n",
      "        nan 0.69379845]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe_logreg2 = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('logreg', LogisticRegression(solver = 'liblinear'))\n",
    "])\n",
    "\n",
    "params_logreg2 = {\n",
    "    'cvec__stop_words' : [None, 'english'],\n",
    "    'logreg__penalty' : ['none','l2'],\n",
    "    'cvec__max_features': [2000, 3000, 4000, 5000],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "\n",
    "gs_logreg2 = GridSearchCV(pipe_logreg2, # what object are we optimizing?\n",
    "                  params_logreg2, # what parameters values are we searching?\n",
    "                  cv=5) # 5-fold cross-validation.\n",
    "gs_logreg2.fit(X_train2, y_train2)\n",
    "\n",
    "with open(\"./pickles/gs_logreg2_4b.pkl\", 'wb') as f:\n",
    "    pickle.dump(gs_logreg2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.9534883720930233\n",
      "test score: 0.7308584686774942\n",
      "Accuracy Score: 0.7308584686774942\n",
      "Precision Score: 0.7555555555555555\n",
      "Recall Score: 0.7359307359307359\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted wasn't answered</th>\n",
       "      <th>Predicted was answered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual wasn't answered</th>\n",
       "      <td>145</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual was answered</th>\n",
       "      <td>61</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Predicted wasn't answered  Predicted was answered\n",
       "Actual wasn't answered                        145                      55\n",
       "Actual was answered                            61                     170"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-load grid-search object so do not have to re-run the model if accessing notebook later\n",
    "with open(\"./pickles/gs_logreg2_4b.pkl\", 'rb') as f:\n",
    "    gs_logreg2_loaded = pickle.load(f)\n",
    "\n",
    "gs_logreg2_model = gs_logreg2_loaded.best_estimator_\n",
    "print(\"train score:\", gs_logreg2_model.score(X_train2, y_train2))\n",
    "print(\"test score:\", gs_logreg2_model.score(X_test2, y_test2))\n",
    "\n",
    "preds = gs_logreg2_loaded.best_estimator_.predict(X_test2)\n",
    "make_confusion(y_test2, preds, [\"wasn't answered\", \"was answered\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words Most Indicative of a Question Being Answered.\n",
    "Below I set up and output a dataframe with the coefficients (words most indicative to questions being answered or not answered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = gs_logreg2_loaded.best_estimator_.named_steps['logreg'].coef_[0]\n",
    "features = gs_logreg2_loaded.best_estimator_.named_steps['cvec'].get_feature_names_out()\n",
    "coef_df = pd.DataFrame({'features' : features,\n",
    "             'coefficients': coefs})\n",
    "coef_df.sort_values('coefficients', ascending = False);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words most indicative to the question being answered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>development</td>\n",
       "      <td>1.442892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>love</td>\n",
       "      <td>1.241910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>teaching</td>\n",
       "      <td>1.178190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>accounting</td>\n",
       "      <td>1.132492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>military</td>\n",
       "      <td>1.123589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>art</td>\n",
       "      <td>1.081071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>police</td>\n",
       "      <td>1.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>software</td>\n",
       "      <td>0.994518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>use</td>\n",
       "      <td>0.962368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>computer</td>\n",
       "      <td>0.957115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>entrepreneurship</td>\n",
       "      <td>0.948288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>social</td>\n",
       "      <td>0.921662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>hard</td>\n",
       "      <td>0.916951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>video</td>\n",
       "      <td>0.904349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>general</td>\n",
       "      <td>0.901164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>save</td>\n",
       "      <td>0.899383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>care</td>\n",
       "      <td>0.896427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>graphic</td>\n",
       "      <td>0.892081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>grades</td>\n",
       "      <td>0.890029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>marketing</td>\n",
       "      <td>0.889265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>higher</td>\n",
       "      <td>0.878691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>ready</td>\n",
       "      <td>0.876459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>th</td>\n",
       "      <td>0.873356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>happen</td>\n",
       "      <td>0.873153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>doctor</td>\n",
       "      <td>0.869782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>wanted</td>\n",
       "      <td>0.861062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>open</td>\n",
       "      <td>0.860376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>hi</td>\n",
       "      <td>0.845729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>experiences</td>\n",
       "      <td>0.840091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2139</th>\n",
       "      <td>relations</td>\n",
       "      <td>0.832074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2543</th>\n",
       "      <td>stuck</td>\n",
       "      <td>0.831063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>mental</td>\n",
       "      <td>0.830404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>graduate</td>\n",
       "      <td>0.830023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2954</th>\n",
       "      <td>wont</td>\n",
       "      <td>0.826226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>mentoring</td>\n",
       "      <td>0.822950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>thinking</td>\n",
       "      <td>0.820741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>english</td>\n",
       "      <td>0.816374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>professor</td>\n",
       "      <td>0.815039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>jobs</td>\n",
       "      <td>0.814851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>trying</td>\n",
       "      <td>0.810402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>accountant</td>\n",
       "      <td>0.801266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>salary</td>\n",
       "      <td>0.794323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>career</td>\n",
       "      <td>0.780465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>careers</td>\n",
       "      <td>0.776271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>completed</td>\n",
       "      <td>0.764637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>teacher</td>\n",
       "      <td>0.740165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>indecisive</td>\n",
       "      <td>0.731269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2449</th>\n",
       "      <td>specialist</td>\n",
       "      <td>0.718118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>athletics</td>\n",
       "      <td>0.709874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>thing</td>\n",
       "      <td>0.707118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              features  coefficients\n",
       "914        development      1.442892\n",
       "1563              love      1.241910\n",
       "2633          teaching      1.178190\n",
       "28          accounting      1.132492\n",
       "1631          military      1.123589\n",
       "238                art      1.081071\n",
       "1865            police      1.001188\n",
       "2411          software      0.994518\n",
       "2833               use      0.962368\n",
       "678           computer      0.957115\n",
       "1128  entrepreneurship      0.948288\n",
       "2406            social      0.921662\n",
       "1329              hard      0.916951\n",
       "2868             video      0.904349\n",
       "1269           general      0.901164\n",
       "2241              save      0.899383\n",
       "498               care      0.896427\n",
       "1304           graphic      0.892081\n",
       "1296            grades      0.890029\n",
       "1591         marketing      0.889265\n",
       "1351            higher      0.878691\n",
       "2077             ready      0.876459\n",
       "2672                th      0.873356\n",
       "1326            happen      0.873153\n",
       "979             doctor      0.869782\n",
       "2892            wanted      0.861062\n",
       "1729              open      0.860376\n",
       "1349                hi      0.845729\n",
       "1178       experiences      0.840091\n",
       "2139         relations      0.832074\n",
       "2543             stuck      0.831063\n",
       "1619            mental      0.830404\n",
       "1297          graduate      0.830023\n",
       "2954              wont      0.826226\n",
       "1621         mentoring      0.822950\n",
       "2692          thinking      0.820741\n",
       "1110           english      0.816374\n",
       "1971         professor      0.815039\n",
       "1474              jobs      0.814851\n",
       "2767            trying      0.810402\n",
       "27          accountant      0.801266\n",
       "2231            salary      0.794323\n",
       "500             career      0.780465\n",
       "502            careers      0.776271\n",
       "675          completed      0.764637\n",
       "2631           teacher      0.740165\n",
       "1418        indecisive      0.731269\n",
       "2449        specialist      0.718118\n",
       "283          athletics      0.709874\n",
       "2689             thing      0.707118"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values('coefficients', ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words most indicative to the question NOT being answered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>route</td>\n",
       "      <td>-0.662515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>tips</td>\n",
       "      <td>-0.663635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>applications</td>\n",
       "      <td>-0.665342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2448</th>\n",
       "      <td>special</td>\n",
       "      <td>-0.668941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>orthodontist</td>\n",
       "      <td>-0.669888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>choice</td>\n",
       "      <td>-0.679309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>set</td>\n",
       "      <td>-0.683654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>biology</td>\n",
       "      <td>-0.684434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>criminaljustice</td>\n",
       "      <td>-0.685621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>private</td>\n",
       "      <td>-0.689055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2942</th>\n",
       "      <td>willing</td>\n",
       "      <td>-0.691432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>forensics</td>\n",
       "      <td>-0.693277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>likely</td>\n",
       "      <td>-0.697726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>pediatric</td>\n",
       "      <td>-0.697753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>speech</td>\n",
       "      <td>-0.698598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>minor</td>\n",
       "      <td>-0.713614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>surgeon</td>\n",
       "      <td>-0.714052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>hospital</td>\n",
       "      <td>-0.714460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>come</td>\n",
       "      <td>-0.714724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>record</td>\n",
       "      <td>-0.719602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>worth</td>\n",
       "      <td>-0.726371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>exams</td>\n",
       "      <td>-0.729285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>kinesiology</td>\n",
       "      <td>-0.735219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2305</th>\n",
       "      <td>selection</td>\n",
       "      <td>-0.737592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>boost</td>\n",
       "      <td>-0.742281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>challenges</td>\n",
       "      <td>-0.753731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>aid</td>\n",
       "      <td>-0.758636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>advanced</td>\n",
       "      <td>-0.763006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>environment</td>\n",
       "      <td>-0.770698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>grader</td>\n",
       "      <td>-0.772698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>animal</td>\n",
       "      <td>-0.776721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>qualities</td>\n",
       "      <td>-0.782505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>tutoring</td>\n",
       "      <td>-0.783056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>pediatrics</td>\n",
       "      <td>-0.793857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>choosing</td>\n",
       "      <td>-0.794231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>anthropology</td>\n",
       "      <td>-0.799299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>exam</td>\n",
       "      <td>-0.800751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>confused</td>\n",
       "      <td>-0.803815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>schooling</td>\n",
       "      <td>-0.810027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2263</th>\n",
       "      <td>scholarships</td>\n",
       "      <td>-0.813897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>uc</td>\n",
       "      <td>-0.817174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>mcat</td>\n",
       "      <td>-0.822626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>gap</td>\n",
       "      <td>-0.847605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>looking</td>\n",
       "      <td>-0.857253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>state</td>\n",
       "      <td>-0.865843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>biomedical</td>\n",
       "      <td>-0.965060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1843</th>\n",
       "      <td>places</td>\n",
       "      <td>-0.989168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>sure</td>\n",
       "      <td>-1.020490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>computers</td>\n",
       "      <td>-1.032476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>federal</td>\n",
       "      <td>-1.184114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             features  coefficients\n",
       "2210            route     -0.662515\n",
       "2704             tips     -0.663635\n",
       "205      applications     -0.665342\n",
       "2448          special     -0.668941\n",
       "1748     orthodontist     -0.669888\n",
       "569            choice     -0.679309\n",
       "2328              set     -0.683654\n",
       "400           biology     -0.684434\n",
       "788   criminaljustice     -0.685621\n",
       "1950          private     -0.689055\n",
       "2942          willing     -0.691432\n",
       "1244        forensics     -0.693277\n",
       "1534           likely     -0.697726\n",
       "1791        pediatric     -0.697753\n",
       "2463           speech     -0.698598\n",
       "1634            minor     -0.713614\n",
       "2590          surgeon     -0.714052\n",
       "1370         hospital     -0.714460\n",
       "644              come     -0.714724\n",
       "2103           record     -0.719602\n",
       "2976            worth     -0.726371\n",
       "1168            exams     -0.729285\n",
       "1495      kinesiology     -0.735219\n",
       "2305        selection     -0.737592\n",
       "422             boost     -0.742281\n",
       "534        challenges     -0.753731\n",
       "116               aid     -0.758636\n",
       "74           advanced     -0.763006\n",
       "1132      environment     -0.770698\n",
       "1295           grader     -0.772698\n",
       "170            animal     -0.776721\n",
       "2039        qualities     -0.782505\n",
       "2772         tutoring     -0.783056\n",
       "1793       pediatrics     -0.793857\n",
       "573          choosing     -0.794231\n",
       "187      anthropology     -0.799299\n",
       "1165             exam     -0.800751\n",
       "693          confused     -0.803815\n",
       "2267        schooling     -0.810027\n",
       "2263     scholarships     -0.813897\n",
       "2781               uc     -0.817174\n",
       "1602             mcat     -0.822626\n",
       "1267              gap     -0.847605\n",
       "1557          looking     -0.857253\n",
       "2498            state     -0.865843\n",
       "401        biomedical     -0.965060\n",
       "1843           places     -0.989168\n",
       "2589             sure     -1.020490\n",
       "679         computers     -1.032476\n",
       "1204          federal     -1.184114"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values('coefficients', ascending = False).tail(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thank You!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "378.075px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 482.482888,
   "position": {
    "height": "40px",
    "left": "945.106px",
    "right": "20px",
    "top": "122.99px",
    "width": "578.655px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
