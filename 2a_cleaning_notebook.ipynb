{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-Notebook\" data-toc-modified-id=\"Cleaning-Notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning Notebook</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importing-libarires\" data-toc-modified-id=\"Importing-libarires-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Importing libarires</a></span></li><li><span><a href=\"#Reading-in-the-data\" data-toc-modified-id=\"Reading-in-the-data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Reading in the data</a></span></li><li><span><a href=\"#Sorting-the-Data\" data-toc-modified-id=\"Sorting-the-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Sorting the Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Configuring-Data-Types\" data-toc-modified-id=\"Configuring-Data-Types-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Configuring Data Types</a></span></li><li><span><a href=\"#Creating-Boolean-Columns\" data-toc-modified-id=\"Creating-Boolean-Columns-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Creating Boolean Columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-an-was_answered-Column\" data-toc-modified-id=\"Creating-an-was_answered-Column-1.3.2.1\"><span class=\"toc-item-num\">1.3.2.1&nbsp;&nbsp;</span>Creating an <code>was_answered</code> Column</a></span></li><li><span><a href=\"#Creating-a-has_tag-column\" data-toc-modified-id=\"Creating-a-has_tag-column-1.3.2.2\"><span class=\"toc-item-num\">1.3.2.2&nbsp;&nbsp;</span>Creating a <code>has_tag</code> column</a></span></li></ul></li></ul></li><li><span><a href=\"#Handling-Nulls\" data-toc-modified-id=\"Handling-Nulls-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Handling Nulls</a></span><ul class=\"toc-item\"><li><span><a href=\"#For-columns-with-'object'-type-data,-we're-replacing-nulls-with-&quot;none&quot;\" data-toc-modified-id=\"For-columns-with-'object'-type-data,-we're-replacing-nulls-with-&quot;none&quot;-1.4.1\"><span class=\"toc-item-num\">1.4.1&nbsp;&nbsp;</span>For columns with 'object' type data, we're replacing nulls with \"none\"</a></span></li><li><span><a href=\"#Replace-columns-with-interger/float-data-type-with-0\" data-toc-modified-id=\"Replace-columns-with-interger/float-data-type-with-0-1.4.2\"><span class=\"toc-item-num\">1.4.2&nbsp;&nbsp;</span>Replace columns with <code>interger/float</code> data type with 0</a></span></li></ul></li><li><span><a href=\"#Handling-Duplicates\" data-toc-modified-id=\"Handling-Duplicates-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Handling Duplicates</a></span></li><li><span><a href=\"#Natural-Language-Processing-Cleaning\" data-toc-modified-id=\"Natural-Language-Processing-Cleaning-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Natural Language Processing Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Setting-up-a-Text-Cleaning-Function:\" data-toc-modified-id=\"Setting-up-a-Text-Cleaning-Function:-1.6.1\"><span class=\"toc-item-num\">1.6.1&nbsp;&nbsp;</span>Setting up a Text Cleaning Function:</a></span></li><li><span><a href=\"#Clean-the-Data\" data-toc-modified-id=\"Clean-the-Data-1.6.2\"><span class=\"toc-item-num\">1.6.2&nbsp;&nbsp;</span>Clean the Data</a></span></li></ul></li><li><span><a href=\"#Exporting-Data\" data-toc-modified-id=\"Exporting-Data-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Exporting Data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Notebook\n",
    "\n",
    "Before conducting EDA and building a model the data needs to be formatted in a way that won't throw errors. In a combination of initial exploration and later EDA the following steps are needed:\n",
    "\n",
    "1. Converting to Appropriate Datatype\n",
    "2. Sorting Data\n",
    "3. Handling Nulls\n",
    "4. Dealing with Duplicate Values Left Over from Merging\n",
    "5. Cleaning Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libarires\n",
    "\n",
    "For this notebook we'll use pandas, regex (for cleaning text), and seaborn (for visualizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# from sklearn.feature_extraction import stop_words, text\n",
    "\n",
    "# This creates HD resolution for visualizations\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data\n",
    "\n",
    "An initial look at the dataframe reveals that the text for `answers_body` has several HTML artifacts. In the NLP cleaning later we'll remove these as well as clean other text columns are a precaution. \n",
    "\n",
    "Another thing we notice off the bat is the size of the merged dataframe is 180k rows. However, the number of questions from the questions.csv raw data has ~23.9k rows. We know that this is an error from merging, where question data has been duplicated due to multiple tags (total ~76.5k) and answers (total ~51.1k) per question. Through cleaning and EDA this error persists and essentially gives us unbalanced classes in the 4a_Unsampled_Modeling notebook. Due to limited time, we were not able to fix this error. For better results, I recommend finding a way to resolve this data duplication issue.\n",
    "\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (180376, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_score</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26 UTC+0000</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14147.0</td>\n",
       "      <td>lecture</td>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>2016-04-29 19:40:14 UTC+0000</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26 UTC+0000</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27490.0</td>\n",
       "      <td>college</td>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>2016-04-29 19:40:14 UTC+0000</td>\n",
       "      <td>&lt;p&gt;Hi!&lt;/p&gt;\\n&lt;p&gt;You are asking a very interesti...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "\n",
       "           questions_date_added              questions_title  \\\n",
       "0  2016-04-26 11:14:26 UTC+0000  Teacher   career   question   \n",
       "1  2016-04-26 11:14:26 UTC+0000  Teacher   career   question   \n",
       "\n",
       "                                      questions_body  questions_score  \\\n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...              1.0   \n",
       "1  What  is  a  maths  teacher?   what  is  a  ma...              1.0   \n",
       "\n",
       "    tag_id tag_name                        answers_id  \\\n",
       "0  14147.0  lecture  4e5f01128cae4f6d8fd697cec5dca60c   \n",
       "1  27490.0  college  4e5f01128cae4f6d8fd697cec5dca60c   \n",
       "\n",
       "                  answers_author_id            answers_date_added  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e  2016-04-29 19:40:14 UTC+0000   \n",
       "1  36ff3b3666df400f956f8335cf53e09e  2016-04-29 19:40:14 UTC+0000   \n",
       "\n",
       "                                        answers_body  answers_score  \n",
       "0  <p>Hi!</p>\\n<p>You are asking a very interesti...            0.0  \n",
       "1  <p>Hi!</p>\\n<p>You are asking a very interesti...            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Datasets/df_merged.csv')\n",
    "print(\"shape:\", data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data.describe() reveals a quick overview of the numeric columns. A peruse over the stats shows that there are no noticible outliers that need to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_score</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>answers_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180350.000000</td>\n",
       "      <td>178676.000000</td>\n",
       "      <td>177990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.873818</td>\n",
       "      <td>17010.555682</td>\n",
       "      <td>0.454424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.537048</td>\n",
       "      <td>10196.886662</td>\n",
       "      <td>0.940910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>11051.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>18356.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>25647.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>39250.000000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       questions_score         tag_id  answers_score\n",
       "count    180350.000000  178676.000000  177990.000000\n",
       "mean          4.873818   17010.555682       0.454424\n",
       "std           7.537048   10196.886662       0.940910\n",
       "min           0.000000      27.000000       0.000000\n",
       "25%           2.000000   11051.000000       0.000000\n",
       "50%           4.000000   18356.000000       0.000000\n",
       "75%           5.000000   25647.000000       1.000000\n",
       "max         125.000000   39250.000000      30.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the datatypes I discovered:\n",
    "    \n",
    "    1. Dates are saved as *objects*; we'll change these to datetime\n",
    "    2. ID's are stored as *objects*\n",
    "        a. in checking the dataframe above we see that ID's use both numbers and letters and should stay *objects* \n",
    "        b. That said, when doing our NLP training these should be treated differently than the other *object* columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id             object\n",
       "questions_author_id      object\n",
       "questions_date_added     object\n",
       "questions_title          object\n",
       "questions_body           object\n",
       "questions_score         float64\n",
       "tag_id                  float64\n",
       "tag_name                 object\n",
       "answers_id               object\n",
       "answers_author_id        object\n",
       "answers_date_added       object\n",
       "answers_body             object\n",
       "answers_score           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id                         object\n",
       "questions_author_id                  object\n",
       "questions_date_added    datetime64[ns, UTC]\n",
       "questions_title                      object\n",
       "questions_body                       object\n",
       "questions_score                     float64\n",
       "tag_id                              float64\n",
       "tag_name                             object\n",
       "answers_id                           object\n",
       "answers_author_id                    object\n",
       "answers_date_added      datetime64[ns, UTC]\n",
       "answers_body                         object\n",
       "answers_score                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Creating a `date_cols` list so we can loop through and convert dates to date_time data type\n",
    "\n",
    "date_cols = []\n",
    "\n",
    "for cols in data.columns:\n",
    "    if \"date\" in cols:\n",
    "        date_cols.append(cols)\n",
    "        \n",
    "date_cols\n",
    "\n",
    "#### Converting Date Columns to *Date* type\n",
    "\n",
    "for cols in date_cols:\n",
    "    data[cols] = pd.to_datetime(data[cols])\n",
    "    \n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting columns which are *object* oriented type and saving them as a list called `str_cols`. We do this so we can easily process all the *object* types in the `cleaning_text` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['questions_id', 'questions_author_id', 'questions_title',\n",
       "       'questions_body', 'tag_name', 'answers_id', 'answers_author_id',\n",
       "       'answers_body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_cols = data.select_dtypes(include ='object').columns\n",
    "str_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the various *object* type columns I realized that the `id` columns shouldn't be treated as a string. Since they include both numbers and letters, we cannot convert them into an integer. So instead let's create a list, `text_cols` that contains all the *object* type columns excluding the `id` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['questions_title', 'questions_body', 'tag_name', 'answers_body']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cols = [] #create a list\n",
    "\n",
    "for cols in str_cols: # looping through the `str_cols` variable\n",
    "\n",
    "    if \"id\" not in cols: # if `id` isn't in the name \n",
    "        text_cols.append(cols) # append to `text_cols` list\n",
    "\n",
    "text_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Boolean Columns\n",
    "\n",
    "Before we handle nulls, we want to know if 1) the question was answered and 2) if the question was tagged or not. To do this, we selected an answer and tag column and mapped 0 where there were nulls and 1 for not-nulls to the new `qa_match` and `has_tag` columns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating an `was_answered` Column\n",
    "    \n",
    "Creating a column called `was_answered`, to indicate if the question was answered. `0` if there no answer and `1` if there is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    178036\n",
       "0      2340\n",
       "Name: was_answered, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new column called `was_answered`\n",
    "# Where there are notnulls in a `answer_id`: label 1; if there are nulls: label 0\n",
    "\n",
    "data['was_answered'] = data['answers_id'].notnull().astype(int)\n",
    "data['was_answered'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a `has_tag` column\n",
    "\n",
    "This column has 1 if the row has a tag, and 0, if it doesn't. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called `has_tag`\n",
    "# Where there are notnulls in a `tag_id`: label 1; if there are nulls: label 0\n",
    "\n",
    "data['has_tag'] = data['tag_id'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    178676\n",
       "0      1700\n",
       "Name: has_tag, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['has_tag'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of our models and code do not work when null values are present. We need to either delete or fill the nulls so that later we won't incur any errors.\n",
    "\n",
    "A major contributor to nulls in this dataset is from how the data was given to us. There were 15 datasets that didn't perfectly match. This led to null values where absense of matches occurred, and also a significant duplication of some of the data where there was a one-to-many match.\n",
    "\n",
    "First, we need to check for nulls.\n",
    "\n",
    "<span style = 'color:red'> For now we're just filling nulls. In further merging, cleaning and EDA, the duplicate and null values are handled in a way that does not impact the analysis significantly.\n",
    "    \n",
    "#TODO : consider removing the unnecessary merging, cleaning and EDA - for a potential employer we don't want to distract them. We can keep this working notebook for reference or in case an interview wants to see it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id               0\n",
       "questions_author_id        0\n",
       "questions_date_added       0\n",
       "questions_title            0\n",
       "questions_body             0\n",
       "questions_score           26\n",
       "tag_id                  1700\n",
       "tag_name                1700\n",
       "answers_id              2340\n",
       "answers_author_id       2340\n",
       "answers_date_added      2340\n",
       "answers_body            2344\n",
       "answers_score           2386\n",
       "was_answered               0\n",
       "has_tag                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id                         object\n",
       "questions_author_id                  object\n",
       "questions_date_added    datetime64[ns, UTC]\n",
       "questions_title                      object\n",
       "questions_body                       object\n",
       "questions_score                     float64\n",
       "tag_id                              float64\n",
       "tag_name                             object\n",
       "answers_id                           object\n",
       "answers_author_id                    object\n",
       "answers_date_added      datetime64[ns, UTC]\n",
       "answers_body                         object\n",
       "answers_score                       float64\n",
       "was_answered                          int32\n",
       "has_tag                               int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For columns with 'object' type data, we're replacing nulls with \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_nulls = ['answers_body', 'answers_author_id', 'answers_id', 'tag_name']\n",
    "\n",
    "for cols in str_nulls:\n",
    "    data[cols].fillna(\"none\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace columns with `interger/float` data type with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_nulls = ['questions_score', 'tag_id', 'answers_score']\n",
    "\n",
    "for cols in int_nulls:\n",
    "    data[cols].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that all of the nulls have been replaced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id               0\n",
       "questions_author_id        0\n",
       "questions_date_added       0\n",
       "questions_title            0\n",
       "questions_body             0\n",
       "questions_score            0\n",
       "tag_id                     0\n",
       "tag_name                   0\n",
       "answers_id                 0\n",
       "answers_author_id          0\n",
       "answers_date_added      2340\n",
       "answers_body               0\n",
       "answers_score              0\n",
       "was_answered               0\n",
       "has_tag                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Duplicates\n",
    "\n",
    "Because of the complications with merging I wanted to check how dirty the data was. That is, how many rows have been duplicated with only one column being different. \n",
    "\n",
    "#TODO : <span style ='color:red'> insert image or make heatmap representing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I checked if there are duplicate rows. There weren't, so we know that at least one value in a row is different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are no duplicate rows, we're now checking which columns have duplicate values. \n",
    "\n",
    "Below, the for-loop iterates through each of the columns. Within the loop, I utilize the method `.duplicated()` to get boolean values then `.sum()` to get a count of how many duplicate values are in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions_id:   156445 duplicate values\n",
      "questions_author_id:   168047 duplicate values\n",
      "questions_date_added:   156507 duplicate values\n",
      "questions_title:   156637 duplicate values\n",
      "questions_body:   156695 duplicate values\n",
      "questions_score:   180301 duplicate values\n",
      "tag_id:   173284 duplicate values\n",
      "tag_name:   173285 duplicate values\n",
      "answers_id:   129252 duplicate values\n",
      "answers_author_id:   170206 duplicate values\n",
      "answers_date_added:   129313 duplicate values\n",
      "answers_body:   129974 duplicate values\n",
      "answers_score:   180353 duplicate values\n",
      "was_answered:   180374 duplicate values\n",
      "has_tag:   180374 duplicate values\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:  #Iterates through all the columns in the data frame\n",
    "    duplicate_sum = data[col].duplicated().sum()  #saves the sum\n",
    "    if duplicate_sum > 0:                                     #If there are more than 0 sums, print:\n",
    "        print(f\"{col}:   {duplicate_sum} duplicate values\")\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180376, 15)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the duplicate values shown above are obviously expected, as in the case of the was_answered and has_tag columns which are boolean. The number of duplicate values is only informative when we recall that the total number of rows in the dataframe are 180376. However, just knowing the number of duplicates still isn't very informative without knowing the number of unique values per column:\n",
    "\n",
    "Similiarly to checking duplicates, we're also checking how many unique values are in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values per column:\n",
      "\n",
      "23931 - questions_id\n",
      "12329 - questions_author_id\n",
      "23869 - questions_date_added\n",
      "23739 - questions_title\n",
      "23681 - questions_body\n",
      "75 - questions_score\n",
      "7092 - tag_id\n",
      "7091 - tag_name\n",
      "51124 - answers_id\n",
      "10170 - answers_author_id\n",
      "51062 - answers_date_added\n",
      "50402 - answers_body\n",
      "23 - answers_score\n",
      "2 - was_answered\n",
      "2 - has_tag\n"
     ]
    }
   ],
   "source": [
    "print(\"unique values per column:\")\n",
    "print(\"\")\n",
    "\n",
    "for col in data.columns:  #Iterates through all the columns in the data frame\n",
    "    print(f\"{data[col].nunique()} - {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately we note that the number of unique values lines up very closely with the size of the questions and answers merged data sets. That is, 23931 and 51123 unique id's respectively. \n",
    "\n",
    "Interestingly though, the raw tags.csv data set had 16269 unique values, yet there are only 7092 unique tag id's in the merged data set. There must be a lot of unused tags!\n",
    "\n",
    "Some of the other interesting things to note:\n",
    " - questions_author_id : 12329 unique question askers; on average question authors ask two questions\n",
    " - questions_title : turns out there are some duplicate questions!\n",
    " - questions_body : some questions bodies are duplicated too? perhaps they are empty.\n",
    " - answers_author_id : 10170 authors of answers. on average 5 questions are answered by one professional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to explore the text data and build models from the text we need to clean the text of HTML artifacts and standardize the format to get the best results. This will include removing apostrophes, line breaks, and all punctuation so that there is strictly only text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a Text Cleaning Function:\n",
    "\n",
    "The function takes in a column and cleans the text for pre-proccessing. It removes html artifacts as well as punctuation and numbers, and converts the text to all lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(df, df_col):\n",
    "    \"\"\"\n",
    "    df: is the name of Dataframe \n",
    "    df_col: takes in a column name formated as string i.e. \"column_name\" \n",
    "    \n",
    "    This function takes a column and cleans the text for that column. \n",
    "    It removes HTML artifacts suchs as <p> and <br> as as well as punctuation, \n",
    "    and numbers preparing it for processing and modeling. \n",
    "    In addition it makes all the text lower case.\n",
    "    It utilizes the .replace method as well as regex. \n",
    "    It outputs the top 2 rows\n",
    "    \n",
    "    If you haven't yet, the code to import regex is:\n",
    "    import regex as re \n",
    "    #you need to regex import as re or else this code will break\n",
    "    \"\"\"\n",
    "\n",
    "    # Uses .str.reaplce\n",
    "    df[df_col] = df[df_col].str.replace(\"<p>\", \"\") #removes <p>\n",
    "    df[df_col] = df[df_col].str.replace(\"</p>\",\"\") #removes </p>\n",
    "    df[df_col] = df[df_col].str.replace(\"<br>\", \"\") #removes <br>\n",
    "    df[df_col] = df[df_col].str.replace(\"\\n\", \"\")   #removes <\\n>\n",
    "    \n",
    "    #Makes everything lower case\n",
    "    df[df_col] = df[df_col].str.lower()\n",
    "    \n",
    "    # Using regex and lambda \n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('\\/\\/', ' ', x)) # Removing line breaks\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('[\\\\][\\']', '', x)) # Removing apostrophes\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('[^\\w\\s]', ' ', x)) # Removing all punctuation \n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('\\xa0', ' ', x)) # removing xa0\n",
    "    #df[df_col] = df[df_col].map(lambda x: re.sub('\\s[\\/]?r\\/[^\\s]+', ' ', x)) # removing mentions of any subreddit\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x)) # removing urls\n",
    "    \n",
    "    # Keeping numbers for now, if we want to strip numbers, use the below\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x)) # Removes all numbers only keeping letters\n",
    "    \n",
    "    #Displays the top 2 rows\n",
    "    return df[df_col].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "\n",
    "The following for loop interates through `text_cols` list (all the *object* type columns) and cleans the text using `cleaning_text()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in text_cols:\n",
    "    if data[cols].isnull().sum() == 0: #If there aren't any nulls \n",
    "        cleaning_text(data, cols) #Call `cleaning_text` function\n",
    "    else:\n",
    "        print(f\"{cols} has null values, so we're filling with 'none', then calling `cleaning_tex()` function\") #print which columns have nulls \n",
    "        \n",
    "        #Filling nulls with 'none'\n",
    "        data[cols].fillna('none', inplace =True)\n",
    "        \n",
    "        #Then calling the function\n",
    "        cleaning_text(data, cols) #Call `cleaning_text` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_score</th>\n",
       "      <th>tag_id</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>answers_id</th>\n",
       "      <th>answers_author_id</th>\n",
       "      <th>answers_date_added</th>\n",
       "      <th>answers_body</th>\n",
       "      <th>answers_score</th>\n",
       "      <th>was_answered</th>\n",
       "      <th>has_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>teacher   career   question</td>\n",
       "      <td>what  is  a  maths  teacher    what  is  a  ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14147.0</td>\n",
       "      <td>lecture</td>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>2016-04-29 19:40:14+00:00</td>\n",
       "      <td>hi you are asking a very interesting question ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>teacher   career   question</td>\n",
       "      <td>what  is  a  maths  teacher    what  is  a  ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27490.0</td>\n",
       "      <td>college</td>\n",
       "      <td>4e5f01128cae4f6d8fd697cec5dca60c</td>\n",
       "      <td>36ff3b3666df400f956f8335cf53e09e</td>\n",
       "      <td>2016-04-29 19:40:14+00:00</td>\n",
       "      <td>hi you are asking a very interesting question ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "\n",
       "       questions_date_added              questions_title  \\\n",
       "0 2016-04-26 11:14:26+00:00  teacher   career   question   \n",
       "1 2016-04-26 11:14:26+00:00  teacher   career   question   \n",
       "\n",
       "                                      questions_body  questions_score  \\\n",
       "0  what  is  a  maths  teacher    what  is  a  ma...              1.0   \n",
       "1  what  is  a  maths  teacher    what  is  a  ma...              1.0   \n",
       "\n",
       "    tag_id tag_name                        answers_id  \\\n",
       "0  14147.0  lecture  4e5f01128cae4f6d8fd697cec5dca60c   \n",
       "1  27490.0  college  4e5f01128cae4f6d8fd697cec5dca60c   \n",
       "\n",
       "                  answers_author_id        answers_date_added  \\\n",
       "0  36ff3b3666df400f956f8335cf53e09e 2016-04-29 19:40:14+00:00   \n",
       "1  36ff3b3666df400f956f8335cf53e09e 2016-04-29 19:40:14+00:00   \n",
       "\n",
       "                                        answers_body  answers_score  \\\n",
       "0  hi you are asking a very interesting question ...            0.0   \n",
       "1  hi you are asking a very interesting question ...            0.0   \n",
       "\n",
       "   was_answered  has_tag  \n",
       "0             1        1  \n",
       "1             1        1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe if the cleaning function introduced any null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id               0\n",
       "questions_author_id        0\n",
       "questions_date_added       0\n",
       "questions_title            0\n",
       "questions_body             0\n",
       "questions_score            0\n",
       "tag_id                     0\n",
       "tag_name                   0\n",
       "answers_id                 0\n",
       "answers_author_id          0\n",
       "answers_date_added      2340\n",
       "answers_body               0\n",
       "answers_score              0\n",
       "was_answered               0\n",
       "has_tag                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./Datasets/cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "452.222px",
    "width": "577.438px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "718.889px",
    "left": "807.986px",
    "top": "208.099px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 331.727888,
   "position": {
    "height": "40px",
    "left": "1003.12px",
    "right": "20px",
    "top": "99px",
    "width": "362.875px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
