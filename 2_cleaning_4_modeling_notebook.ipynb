{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Cleaning-Notebook\" data-toc-modified-id=\"Cleaning-Notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Cleaning Notebook</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Importing-libarires\" data-toc-modified-id=\"Importing-libarires-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Importing libarires</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reading-in-the-data,-checking-the-shape-and-first-few-rows.\" data-toc-modified-id=\"Reading-in-the-data,-checking-the-shape-and-first-few-rows.-1.0.1.1\"><span class=\"toc-item-num\">1.0.1.1&nbsp;&nbsp;</span>Reading in the data, checking the shape and first few rows.</a></span></li><li><span><a href=\"#Extracting-columns-which-are-object-oriented-type-and-saving-them-as-a-list-called-str_cols.-We-do-this-so-we-can-easily-process-all-the-object-types-in-the-cleaning_text-function.\" data-toc-modified-id=\"Extracting-columns-which-are-object-oriented-type-and-saving-them-as-a-list-called-str_cols.-We-do-this-so-we-can-easily-process-all-the-object-types-in-the-cleaning_text-function.-1.0.1.2\"><span class=\"toc-item-num\">1.0.1.2&nbsp;&nbsp;</span>Extracting columns which are <em>object</em> oriented type and saving them as a list called <code>str_cols</code>. We do this so we can easily process all the <em>object</em> types in the <code>cleaning_text</code> function.</a></span></li><li><span><a href=\"#Using-a-for-loop-to-create-text_cols-list-which-is-a-list-of-columns-that-are-text-based-(object-columns-that-aren't-id-columns)\" data-toc-modified-id=\"Using-a-for-loop-to-create-text_cols-list-which-is-a-list-of-columns-that-are-text-based-(object-columns-that-aren't-id-columns)-1.0.1.3\"><span class=\"toc-item-num\">1.0.1.3&nbsp;&nbsp;</span>Using a for loop to create <code>text_cols</code> list which is a list of columns that are text based (<em>object</em> columns that aren't <code>id</code> columns)</a></span></li></ul></li><li><span><a href=\"#Handling-Nulls:\" data-toc-modified-id=\"Handling-Nulls:-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Handling Nulls:</a></span></li></ul></li><li><span><a href=\"#-For-now-we're-just-filling-nulls.\" data-toc-modified-id=\"-For-now-we're-just-filling-nulls.-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span><span style=\"color:red\"> For now we're just filling nulls.</span></a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Filling-nulls\" data-toc-modified-id=\"Filling-nulls-1.1.0.1\"><span class=\"toc-item-num\">1.1.0.1&nbsp;&nbsp;</span>Filling nulls</a></span></li></ul></li></ul></li><li><span><a href=\"#Natural-Language-Processing-Cleaning\" data-toc-modified-id=\"Natural-Language-Processing-Cleaning-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Natural Language Processing Cleaning</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#-explain-more\" data-toc-modified-id=\"-explain-more-1.2.0.1\"><span class=\"toc-item-num\">1.2.0.1&nbsp;&nbsp;</span><span style=\"color:red\"> explain more</span></a></span></li><li><span><a href=\"#Setting-up-a-Cleaning-Text-Function:\" data-toc-modified-id=\"Setting-up-a-Cleaning-Text-Function:-1.2.0.2\"><span class=\"toc-item-num\">1.2.0.2&nbsp;&nbsp;</span>Setting up a Cleaning Text Function:</a></span></li><li><span><a href=\"#For-loop-interates-through-text_cols-list-(all-the-object-oriented-columns)-and-cleans-the-text-using-cleaning_text()-function.\" data-toc-modified-id=\"For-loop-interates-through-text_cols-list-(all-the-object-oriented-columns)-and-cleans-the-text-using-cleaning_text()-function.-1.2.0.3\"><span class=\"toc-item-num\">1.2.0.3&nbsp;&nbsp;</span>For loop interates through <code>text_cols</code> list (all the <em>object</em> oriented columns) and cleans the text using <code>cleaning_text()</code> function.</a></span></li></ul></li></ul></li><li><span><a href=\"#Exporting-Data\" data-toc-modified-id=\"Exporting-Data-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Exporting Data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Notebook\n",
    "\n",
    "Before conducting EDA and building the data needs to be formatted in a way that won't throw errors. In a combination of intial exploration and later EDA the following steps are needed:\n",
    "\n",
    "1. Creating Columns \n",
    "2. Converting to Appropriate Datatype\n",
    "3. Handeling Nulls\n",
    "4. Cleaning Text\n",
    "5. Dealing Duplicate Values Left Over from Merging Madness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libarires\n",
    "\n",
    "For this notebook we'll use pandas, regex (for cleaning text), and seaborn (for visualizations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rwilkening/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# from nltk.tokenize import RegexpTokenizer\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# from sklearn.feature_extraction import stop_words, text\n",
    "\n",
    "# This creates HD resolution for visualizations\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in the data, checking the shape and first few rows.\n",
    "\n",
    "An initial look at the dataframe reveals that the text for `answers_body` has several HTML artifacts. In the NLP cleaning later we'll remove these as well as clean other text columns are a precaution. \n",
    "\n",
    "<span style ='color:red'> include? Or move to merge notebook?? Should start off with a bang\n",
    "One of the things we notice off the bat is that size is 180K rows. From the merging of notebooks we know that this is an error from merging. Through EDA and cleaning this error persists and essentially gives us unbalanced classes while merging. Due to limited time, we weren't able to fix this error. For better results, I recommend fixing this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (51944, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_score</th>\n",
       "      <th>was_answered</th>\n",
       "      <th>answers_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26 UTC+0000</td>\n",
       "      <td>Teacher   career   question</td>\n",
       "      <td>What  is  a  maths  teacher?   what  is  a  ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>acccbda28edd4362ab03fb8b6fd2d67b</td>\n",
       "      <td>2016-05-20 16:48:25 UTC+0000</td>\n",
       "      <td>I want to become an army officer. What can I d...</td>\n",
       "      <td>I am Priyanka from Bangalore . Now am in 10th ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  eb80205482e4424cad8f16bc25aa2d9c  acccbda28edd4362ab03fb8b6fd2d67b   \n",
       "\n",
       "           questions_date_added  \\\n",
       "0  2016-04-26 11:14:26 UTC+0000   \n",
       "1  2016-05-20 16:48:25 UTC+0000   \n",
       "\n",
       "                                     questions_title  \\\n",
       "0                        Teacher   career   question   \n",
       "1  I want to become an army officer. What can I d...   \n",
       "\n",
       "                                      questions_body  questions_score  \\\n",
       "0  What  is  a  maths  teacher?   what  is  a  ma...              1.0   \n",
       "1  I am Priyanka from Bangalore . Now am in 10th ...              5.0   \n",
       "\n",
       "   was_answered  answers_score  \n",
       "0           1.0            0.0  \n",
       "1           1.0            0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./Datasets/merged_4_modeling.csv')\n",
    "print(\"shape:\", data.shape)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data.describe() reveals a quick overview of the numeric columns. A peruse over the stats shows that there are no significant outliers that need to be cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_score</th>\n",
       "      <th>was_answered</th>\n",
       "      <th>answers_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51936.000000</td>\n",
       "      <td>51123.0</td>\n",
       "      <td>51107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.530980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.651972</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.921442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>125.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       questions_score  was_answered  answers_score\n",
       "count     51936.000000       51123.0   51107.000000\n",
       "mean          4.530980           1.0       0.415501\n",
       "std           6.651972           0.0       0.921442\n",
       "min           0.000000           1.0       0.000000\n",
       "25%           2.000000           1.0       0.000000\n",
       "50%           3.000000           1.0       0.000000\n",
       "75%           5.000000           1.0       1.000000\n",
       "max         125.000000           1.0      30.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By checking the datatypes I discovered:\n",
    "1. Dates are saved as *objects* we'll change these laters\n",
    "2. Id's are stored as *objects*, in checking the dataframe above we see that id's use both numbers and letters and shouldn't be converted to another datatype. That said, when doing our NLP training these should be treated differently than the other *object* columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id             object\n",
       "questions_author_id      object\n",
       "questions_date_added     object\n",
       "questions_title          object\n",
       "questions_body           object\n",
       "questions_score         float64\n",
       "was_answered            float64\n",
       "answers_score           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id                         object\n",
       "questions_author_id                  object\n",
       "questions_date_added    datetime64[ns, UTC]\n",
       "questions_title                      object\n",
       "questions_body                       object\n",
       "questions_score                     float64\n",
       "was_answered                        float64\n",
       "answers_score                       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Creating a `date_cols` list so we can loop through and convert dates to date_time data type\n",
    "\n",
    "date_cols = []\n",
    "\n",
    "for cols in data.columns:\n",
    "    if \"date\" in cols:\n",
    "        date_cols.append(cols)\n",
    "        \n",
    "date_cols\n",
    "\n",
    "#### Converting Date Columns to *Date* type\n",
    "\n",
    "for cols in date_cols:\n",
    "    data[cols] = pd.to_datetime(data[cols])\n",
    "    \n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting columns which are *object* oriented type and saving them as a list called `str_cols`. We do this so we can easily process all the *object* types in the `cleaning_text` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['questions_id', 'questions_author_id', 'questions_title',\n",
       "       'questions_body'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_cols = data.select_dtypes(include ='object').columns\n",
    "str_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the various *object* type columns I realize that the `id` columns shouldn't be treated as a string. Since they include both numbers and letters, we can't convert them into a interger. So instead let's create a list, `text_cols` that has all *object* type columns excluding the `id` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using a for loop to create `text_cols` list which is a list of columns that are text based (*object* columns that aren't `id` columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['questions_title', 'questions_body']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cols = [] #create a list\n",
    "\n",
    "for cols in str_cols: # looping through the `str_cols` variable\n",
    "\n",
    "    if \"id\" not in cols: # if `id` isn't in the name \n",
    "        text_cols.append(cols) # append to `text_cols` list\n",
    "\n",
    "text_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Nulls:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of our models and code doesn't work when null values are present. We need to either delete, or fill the nulls so that later we won't incur any errors.\n",
    "\n",
    "A major contributor for nulls in this dataset is from how the data was given to us. There were 15 datasets that didn't perfectly match. We had to choose to either duplicate/create information or to loose information. Since making up information creates more issues, we choose to deal with the large number of nulls values. \n",
    "\n",
    "First we need to check for nulls.\n",
    "\n",
    "## <span style = 'color:red'> For now we're just filling nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "questions_id              0\n",
       "questions_author_id       0\n",
       "questions_date_added      0\n",
       "questions_title           0\n",
       "questions_body            0\n",
       "questions_score           8\n",
       "was_answered            821\n",
       "answers_score           837\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling nulls\n",
    "\n",
    "When merging, all the `was_answered` were '1' representing that it was answered, with no nulls. Since we did a left merge on the questions dataset we know all the nulls are where questions weren't answered. Therefor I'm filling `was_answered` nulls with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['was_answered'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to explore the text data and build models form the text we need to clean the text to get the best results. \n",
    "\n",
    "#### <span style='color:red'> explain more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up a Cleaning Text Function: \n",
    "\n",
    "The function takes in a column and cleans the text for preproccessing. It removes html artifacts as well as punctuation and numbers, and converts the text to all lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_text(df, df_col):\n",
    "    \"\"\"\n",
    "    df: is the name of Dataframe \n",
    "    df_col: takes in a column name formated as string i.e. \"column_name\" \n",
    "    \n",
    "    This function takes a column and cleans the text for that column. \n",
    "    It removes HTML artifacts suchs as <p> and <br> as as well as punctuation, \n",
    "    and numbers preparing it for processing and modeling. \n",
    "    In addition it makes all the text lower case.\n",
    "    It utilizes the .replace method as well as regex. \n",
    "    It outputs the top 2 rows\n",
    "    \n",
    "    If you haven't yet, the code to import regex is:\n",
    "    import regex as re \n",
    "    #you need to regex import as re or else this code will break\n",
    "    \"\"\"\n",
    "\n",
    "    # Uses .str.reaplce\n",
    "    df[df_col] = df[df_col].str.replace(\"<p>\", \"\") #removes <p>\n",
    "    df[df_col] = df[df_col].str.replace(\"</p>\",\"\") #removes </p>\n",
    "    df[df_col] = df[df_col].str.replace(\"<br>\", \"\") #removes <br>\n",
    "    df[df_col] = df[df_col].str.replace(\"\\n\", \"\")   #removes <\\n>\n",
    "    \n",
    "    #Makes everything lower case\n",
    "    df[df_col] = df[df_col].str.lower()\n",
    "    \n",
    "    # Using regex and lambda \n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('\\/\\/', ' ', x)) # Removing line breaks\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('[\\\\][\\']', '', x)) # Removing apostrophes\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('[^\\w\\s]', ' ', x)) # Removing all punctuation \n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('\\xa0', ' ', x)) # removing xa0\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('\\s[\\/]?r\\/[^\\s]+', ' ', x)) # removing mentions of any subreddit\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub('http[s]?:\\/\\/[^\\s]*', ' ', x)) # removing urls\n",
    "    \n",
    "    # Keeping numbers for now, if we want to strip numbers, use the below\n",
    "    df[df_col] = df[df_col].map(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x)) # Removes all numbers only keeping letters\n",
    "    \n",
    "    #Displays the top 2 rows\n",
    "    return df[df_col].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For loop interates through `text_cols` list (all the *object* oriented columns) and cleans the text using `cleaning_text()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cols in text_cols:\n",
    "    if data[cols].isnull().sum() == 0: #If there aren't any nulls \n",
    "        cleaning_text(data, cols) #Call `cleaning_text` function\n",
    "    else:\n",
    "        print(f\"{cols} has null values, so we're filling with 'none', then calling `cleaning_tex()` function\") #print which columns have nulls \n",
    "        \n",
    "        #Filling nulls with 'none'\n",
    "        data[cols].fillna('none', inplace =True)\n",
    "        \n",
    "        #Then calling the function\n",
    "        cleaning_text(data, cols) #Call `cleaning_text` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions_id</th>\n",
       "      <th>questions_author_id</th>\n",
       "      <th>questions_date_added</th>\n",
       "      <th>questions_title</th>\n",
       "      <th>questions_body</th>\n",
       "      <th>questions_score</th>\n",
       "      <th>was_answered</th>\n",
       "      <th>answers_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>332a511f1569444485cf7a7a556a5e54</td>\n",
       "      <td>8f6f374ffd834d258ab69d376dd998f5</td>\n",
       "      <td>2016-04-26 11:14:26+00:00</td>\n",
       "      <td>teacher   career   question</td>\n",
       "      <td>what  is  a  maths  teacher    what  is  a  ma...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eb80205482e4424cad8f16bc25aa2d9c</td>\n",
       "      <td>acccbda28edd4362ab03fb8b6fd2d67b</td>\n",
       "      <td>2016-05-20 16:48:25+00:00</td>\n",
       "      <td>i want to become an army officer  what can i d...</td>\n",
       "      <td>i am priyanka from bangalore   now am in   th ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       questions_id               questions_author_id  \\\n",
       "0  332a511f1569444485cf7a7a556a5e54  8f6f374ffd834d258ab69d376dd998f5   \n",
       "1  eb80205482e4424cad8f16bc25aa2d9c  acccbda28edd4362ab03fb8b6fd2d67b   \n",
       "\n",
       "       questions_date_added  \\\n",
       "0 2016-04-26 11:14:26+00:00   \n",
       "1 2016-05-20 16:48:25+00:00   \n",
       "\n",
       "                                     questions_title  \\\n",
       "0                        teacher   career   question   \n",
       "1  i want to become an army officer  what can i d...   \n",
       "\n",
       "                                      questions_body  questions_score  \\\n",
       "0  what  is  a  maths  teacher    what  is  a  ma...              1.0   \n",
       "1  i am priyanka from bangalore   now am in   th ...              5.0   \n",
       "\n",
       "   was_answered  answers_score  \n",
       "0           1.0            0.0  \n",
       "1           1.0            0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./Datasets/cleaned_4_modeling.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "274.222px",
    "width": "325.222px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.861px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
